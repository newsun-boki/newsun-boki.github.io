<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-11-01T17:29:25.007Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>seaborn入门(6)PairGrid</title>
    <link href="http://example.com/2021/11/02/seaborn6/"/>
    <id>http://example.com/2021/11/02/seaborn6/</id>
    <published>2021-11-01T17:27:36.000Z</published>
    <updated>2021-11-01T17:29:25.007Z</updated>
    
    <content type="html"><![CDATA[<h1 id="seaborn入门-6-PairGrid"><a href="#seaborn入门-6-PairGrid" class="headerlink" title="seaborn入门(6)PairGrid"></a>seaborn入门(6)PairGrid</h1><h2 id="PairGrid"><a href="#PairGrid" class="headerlink" title="PairGrid"></a>PairGrid</h2><p>代码和图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">iris = sns.load_dataset(name=<span class="string">&#x27;iris&#x27;</span>,cache=<span class="literal">True</span>,data_home=<span class="string">&quot;./seaborn-data&quot;</span>)</span><br><span class="line">iris_g = sns.PairGrid(iris,hue = <span class="string">&quot;species&quot;</span>)</span><br><span class="line">iris_g.<span class="built_in">map</span>(plt.scatter)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210130001248178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><p>累了，溜了</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;seaborn入门-6-PairGrid&quot;&gt;&lt;a href=&quot;#seaborn入门-6-PairGrid&quot; class=&quot;headerlink&quot; title=&quot;seaborn入门(6)PairGrid&quot;&gt;&lt;/a&gt;seaborn入门(6)PairGrid&lt;/h1&gt;&lt;</summary>
      
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="seaborn" scheme="http://example.com/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>seaborn入门(5)群图(cluster map)</title>
    <link href="http://example.com/2021/11/02/seaborn5/"/>
    <id>http://example.com/2021/11/02/seaborn5/</id>
    <published>2021-11-01T17:25:33.000Z</published>
    <updated>2021-11-01T17:27:18.964Z</updated>
    
    <content type="html"><![CDATA[<h1 id="seaborn入门-5-群图-cluster-map"><a href="#seaborn入门-5-群图-cluster-map" class="headerlink" title="seaborn入门(5)群图(cluster map)"></a>seaborn入门(5)群图(cluster map)</h1><h2 id="群图-cluster-map"><a href="#群图-cluster-map" class="headerlink" title="群图(cluster map)"></a>群图(cluster map)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">iris = sns.load_dataset(name=<span class="string">&#x27;iris&#x27;</span>,cache=<span class="literal">True</span>,data_home=<span class="string">&quot;./seaborn-data&quot;</span>)</span><br><span class="line">species = iris.pop(<span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(species)</span><br><span class="line">sns.clustermap(iris)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129233342616.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ><br>这图可能有亿点点复杂，但其实很简单(<del>并不是</del>)<br>这就是所谓的<strong>分层聚类热图</strong>，首先计算了点与点之间的距离，最接近的会被加入，然后开始比较行与列之间的关系。（<del>说了个几把</del> ）</p><p><strong>让我们稍微换一个简单一点点的例子</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flights = flights.pivot_table(index = <span class="string">&#x27;month&#x27;</span>,columns = <span class="string">&#x27;year&#x27;</span>, values = <span class="string">&#x27;passengers&#x27;</span>)</span><br><span class="line">flights = flights.pivot_table(index = <span class="string">&#x27;month&#x27;</span>,columns = <span class="string">&#x27;year&#x27;</span>, values = <span class="string">&#x27;passengers&#x27;</span>)</span><br><span class="line">sns.clustermap(flights,cmap = <span class="string">&quot;Blues&quot;</span>, standard_scale=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>flights代表的是一个二维数组，代表某年某月的乘客人数，<a class="link"   href="https://blog.csdn.net/newsunson/article/details/113408300" >详情见<i class="fas fa-external-link-alt"></i></a></p><p>所以我们得到下面的图<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129234934427.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ><br>你会发现年份和月份并不是按着顺序排列的，这其实就是一个相当于聚类的过程，你可以把他看成一个聚类后的热力图（<strong>我以为我懂了，仔细一想我好像还是有点懵，希望大佬们来补充一下</strong>）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;seaborn入门-5-群图-cluster-map&quot;&gt;&lt;a href=&quot;#seaborn入门-5-群图-cluster-map&quot; class=&quot;headerlink&quot; title=&quot;seaborn入门(5)群图(cluster map)&quot;&gt;&lt;/a&gt;seaborn</summary>
      
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="seaborn" scheme="http://example.com/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>seaborn入门(4)关联系数矩阵和热力图</title>
    <link href="http://example.com/2021/11/02/seaborn4/"/>
    <id>http://example.com/2021/11/02/seaborn4/</id>
    <published>2021-11-01T17:24:29.000Z</published>
    <updated>2021-11-01T17:26:51.201Z</updated>
    
    <content type="html"><![CDATA[<h1 id="seaborn入门-4-关联系数矩阵和热力图"><a href="#seaborn入门-4-关联系数矩阵和热力图" class="headerlink" title="seaborn入门(4)关联系数矩阵和热力图"></a>seaborn入门(4)关联系数矩阵和热力图</h1><h2 id="关联系数矩阵"><a href="#关联系数矩阵" class="headerlink" title="关联系数矩阵"></a>关联系数矩阵</h2><p>这个懂的都懂，大概就是表示两个变量之间的关联性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">tips_df = sns.load_dataset(name=<span class="string">&#x27;tips&#x27;</span>,cache=<span class="literal">True</span>,data_home=<span class="string">&quot;./seaborn-data&quot;</span>)</span><br><span class="line">tips_mx = tips_df.corr()</span><br><span class="line"><span class="built_in">print</span>(tips_df.corr())</span><br></pre></td></tr></table></figure><p>载入数据有问题看seaborn入门(1)<br>得到如下结果<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129230000142.png#pic_center"                      alt="在这里插入图片描述"                ></p><h2 id="热力图"><a href="#热力图" class="headerlink" title="热力图"></a>热力图</h2><p>我们可以将上面的矩阵可视化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.heatmap(tips_mx,annot = <span class="literal">True</span> , cmap = <span class="string">&#x27;Blues&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li>其中cmap的选择和<a class="link"   href="https://editor.csdn.net/md/?articleId=113408019" >调色盘<i class="fas fa-external-link-alt"></i></a>一样</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129230758969.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h2 id="酷酷的热力图"><a href="#酷酷的热力图" class="headerlink" title="酷酷的热力图"></a>酷酷的热力图</h2><p>我们采用新的数据，并创建一个数据透视图。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flights = sns.load_dataset(name=<span class="string">&#x27;flights&#x27;</span>,cache=<span class="literal">True</span>,data_home=<span class="string">&quot;./seaborn-data&quot;</span>)</span><br><span class="line"><span class="comment">#数据透视图创建</span></span><br><span class="line">flights = flights.pivot_table(index = <span class="string">&#x27;month&#x27;</span>,columns = <span class="string">&#x27;year&#x27;</span>, values = <span class="string">&#x27;passengers&#x27;</span>)</span><br></pre></td></tr></table></figure><p>原来的数据是这样的<img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129232036805.png#pic_center"                      alt="在这里插入图片描述"                ><br>数据透视图是这样的，表示某年某月某日乘坐飞机的人数</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129231848465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ><br>画成热力图就是<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129232302523.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ><br><del>有种马赛克的美感</del> </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;seaborn入门-4-关联系数矩阵和热力图&quot;&gt;&lt;a href=&quot;#seaborn入门-4-关联系数矩阵和热力图&quot; class=&quot;headerlink&quot; title=&quot;seaborn入门(4)关联系数矩阵和热力图&quot;&gt;&lt;/a&gt;seaborn入门(4)关联系数矩阵和热</summary>
      
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="seaborn" scheme="http://example.com/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>seaborn入门(3)调色盘</title>
    <link href="http://example.com/2021/11/02/seaborn3/"/>
    <id>http://example.com/2021/11/02/seaborn3/</id>
    <published>2021-11-01T17:22:20.000Z</published>
    <updated>2021-11-01T17:25:19.784Z</updated>
    
    <content type="html"><![CDATA[<h1 id="seaborn入门-3-调色盘"><a href="#seaborn入门-3-调色盘" class="headerlink" title="seaborn入门(3)调色盘"></a>seaborn入门(3)调色盘</h1><h2 id="基础准备"><a href="#基础准备" class="headerlink" title="基础准备"></a>基础准备</h2><p>续接上文</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">tips_df = sns.load_dataset(name=<span class="string">&#x27;tips&#x27;</span>,cache=<span class="literal">True</span>,data_home=<span class="string">&quot;./seaborn-data&quot;</span>)</span><br><span class="line">sns.set_style(<span class="string">&#x27;dark&#x27;</span>)</span><br><span class="line">sns.set_context(<span class="string">&#x27;talk&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="调色盘"><a href="#调色盘" class="headerlink" title="调色盘"></a>调色盘</h2><p>访问这个界面你能看到调色看给你的一些风格样式<br><code>https://matplotlib.org/3.3.1/tutorials/colors/colormaps.html</code><br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129224410260.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ><br>例如我选一个夏天风情的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.stripplot(x = <span class="string">&#x27;day&#x27;</span>,y = <span class="string">&#x27;total_bill&#x27;</span>, data = tips_df,jitter = <span class="literal">True</span>,hue = <span class="string">&#x27;sex&#x27;</span>,palette = <span class="string">&#x27;summer&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129225343154.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;seaborn入门-3-调色盘&quot;&gt;&lt;a href=&quot;#seaborn入门-3-调色盘&quot; class=&quot;headerlink&quot; title=&quot;seaborn入门(3)调色盘&quot;&gt;&lt;/a&gt;seaborn入门(3)调色盘&lt;/h1&gt;&lt;h2 id=&quot;基础准备&quot;&gt;&lt;a href</summary>
      
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="seaborn" scheme="http://example.com/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>seaborn入门(2)继续展示seaborn的各种绘图效果</title>
    <link href="http://example.com/2021/11/02/seaborn2/"/>
    <id>http://example.com/2021/11/02/seaborn2/</id>
    <published>2021-11-01T17:17:55.000Z</published>
    <updated>2021-11-01T17:21:44.678Z</updated>
    
    <content type="html"><![CDATA[<h1 id="seaborn入门-2"><a href="#seaborn入门-2" class="headerlink" title="seaborn入门(2)"></a>seaborn入门(2)</h1><h2 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h2><p>续接上文</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">tips_df = sns.load_dataset(name=<span class="string">&#x27;tips&#x27;</span>,cache=<span class="literal">True</span>,data_home=<span class="string">&quot;./seaborn-data&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="设置风格"><a href="#设置风格" class="headerlink" title="设置风格"></a>设置风格</h2><p>共有4种风格可以选，分别是”white”, “dark”, “whitegrid”, “darkgrid”, “ticks”。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.set_style(<span class="string">&quot;dark&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="简单设置图中元素"><a href="#简单设置图中元素" class="headerlink" title="简单设置图中元素"></a>简单设置图中元素</h2><ul><li>设置画布大小</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">4</span>))</span><br></pre></td></tr></table></figure><ul><li>设置字体</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.set_context(<span class="string">&#x27;paper&#x27;</span>,font_scale=<span class="number">1.4</span>) </span><br></pre></td></tr></table></figure><blockquote><p>其中’paper’为风格，还有talk,poster等风格</p></blockquote><ul><li>设置坐标轴<br>例如下面的代码是删除左边的坐标轴，同理还可以设置<code>bottom = True</code>。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.despine(left = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li></ul><h2 id="柱状图"><a href="#柱状图" class="headerlink" title="柱状图"></a>柱状图</h2><p>男性女性给的小费差异，默认来看是通过男性给小费的平均值和女性给小费的平均值来进行比较，也可以通过中位数<code>estimator = np.media</code>，标准差<code>np.std</code>，协方差<code>np.cov来估计</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.barplot(x = <span class="string">&#x27;sex&#x27;</span>, y = <span class="string">&#x27;total_bill&#x27;</span>, data = tips_df, estimator=np.mean)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129203730986.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h2 id="计数图"><a href="#计数图" class="headerlink" title="计数图"></a>计数图</h2><p>与之相比，计数图可以对某个数据集统计数量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(x = <span class="string">&#x27;sex&#x27;</span>, data = tips_df)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129221529262.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h2 id="箱型图"><a href="#箱型图" class="headerlink" title="箱型图"></a>箱型图</h2><p>这种图不是很懂啊，希望有大佬来分析以下QwQ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.boxplot(x = <span class="string">&#x27;day&#x27;</span>,y = <span class="string">&#x27;total_bill&#x27;</span>, data = tips_df, hue = <span class="string">&#x27;sex&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129221720323.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h2 id="小提琴图"><a href="#小提琴图" class="headerlink" title="小提琴图"></a>小提琴图</h2><p>同上，感觉这图有点骚,大概就是代表数据的分布。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.violinplot(x = <span class="string">&#x27;day&#x27;</span>,y = <span class="string">&#x27;total_bill&#x27;</span>, data = tips_df, hue = <span class="string">&#x27;sex&#x27;</span>,split = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129221827101.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h2 id="剥离图"><a href="#剥离图" class="headerlink" title="剥离图"></a>剥离图</h2><p>这是一个代表不同数据点的散点图，其中一个变量是分类变量，代表着数据的平均分布</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.stripplot(x = <span class="string">&#x27;day&#x27;</span>,y = <span class="string">&#x27;total_bill&#x27;</span>, data = tips_df,jitter = <span class="literal">True</span>,)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129222746989.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h2 id="分簇散点图"><a href="#分簇散点图" class="headerlink" title="分簇散点图"></a>分簇散点图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.swarmplot(x  = <span class="string">&#x27;day&#x27;</span>,y = <span class="string">&#x27;total_bill&#x27;</span>, data = tips_df)</span><br></pre></td></tr></table></figure><p>算是小提琴图的点状形式吧<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129223303445.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;seaborn入门-2&quot;&gt;&lt;a href=&quot;#seaborn入门-2&quot; class=&quot;headerlink&quot; title=&quot;seaborn入门(2)&quot;&gt;&lt;/a&gt;seaborn入门(2)&lt;/h1&gt;&lt;h2 id=&quot;准备数据集&quot;&gt;&lt;a href=&quot;#准备数据集&quot; cla</summary>
      
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="seaborn" scheme="http://example.com/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>seaborn入门(1)展示seaborn的各种绘图效果</title>
    <link href="http://example.com/2021/11/02/seaborn1/"/>
    <id>http://example.com/2021/11/02/seaborn1/</id>
    <published>2021-11-01T17:13:33.000Z</published>
    <updated>2021-11-01T17:19:10.092Z</updated>
    
    <content type="html"><![CDATA[<h1 id="seaborn入门-1-展示seaborn的各种绘图效果"><a href="#seaborn入门-1-展示seaborn的各种绘图效果" class="headerlink" title="seaborn入门(1)展示seaborn的各种绘图效果"></a>seaborn入门(1)展示seaborn的各种绘图效果</h1><h2 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br></pre></td></tr></table></figure><h2 id="载入数据集"><a href="#载入数据集" class="headerlink" title="载入数据集"></a>载入数据集</h2><p>以下代码可以查看seaborn自带的数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(sns.get_dataset_names())</span><br></pre></td></tr></table></figure><p>这里使用<strong>车祸信息</strong>作为原始数据集,按理来说下面代码就可以实现导入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crash_df = sns.load_dataset(<span class="string">&quot;car_crashes&quot;</span>)</span><br></pre></td></tr></table></figure><p>但实际上，由于不可描述的某种抗力，导致在下载数据集的时候有可能下载不出来(<del>如果你加载出来了当我没说</del>)，所以<strong>需要到github上提前下载数据集</strong>(<a class="link"   href="https://github.com/mwaskom/seaborn-data" >https://github.com/mwaskom/seaborn-data<i class="fas fa-external-link-alt"></i></a>)<u>(建议先导入码云之后再下载)</u>，下载之后将数据集放入与文件相同的目录下，然后使用以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crash_df = sns.load_dataset(name=<span class="string">&quot;car_crashes&quot;</span>,cache=<span class="literal">True</span>,data_home=<span class="string">&quot;./seaborn-data&quot;</span>)</span><br></pre></td></tr></table></figure><p>现在可以查看表的内容了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(crash_df.head())</span><br></pre></td></tr></table></figure><h2 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h2><p>首先，选择你的风格,分别是”white”, “dark”, “whitegrid”, “darkgrid”, “ticks”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.set_style(<span class="string">&#x27;white&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="简单展示几种绘图方式"><a href="#简单展示几种绘图方式" class="headerlink" title="简单展示几种绘图方式"></a>简单展示几种绘图方式</h3><h4 id="displot"><a href="#displot" class="headerlink" title="displot()"></a>displot()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.displot(crash_df[<span class="string">&#x27;not_distracted&#x27;</span>],kde = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129195444571.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h4 id="kdeplot"><a href="#kdeplot" class="headerlink" title="kdeplot()"></a>kdeplot()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.kdeplot(crash_df[<span class="string">&#x27;speeding&#x27;</span>],crash_df[<span class="string">&#x27;alcohol&#x27;</span>], data = crash_df, shade = </span><br><span class="line"><span class="literal">True</span> ,cbar=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129195527693.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h4 id="jointplot"><a href="#jointplot" class="headerlink" title="jointplot()"></a>jointplot()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.jointplot(x = <span class="string">&#x27;speeding&#x27;</span>, y = <span class="string">&#x27;alcohol&#x27;</span>, data = crash_df,kind = <span class="string">&#x27;kde&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129195543526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h4 id="pairplot"><a href="#pairplot" class="headerlink" title="pairplot()"></a>pairplot()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.pairplot(crash_df)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129195640960.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><p>或者可以使用<strong>hue</strong>分类<u>（这里重新导入了一个数据集）</u></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tips_df = sns.load_dataset(name=<span class="string">&#x27;tips&#x27;</span>,cache=<span class="literal">True</span>,data_home=<span class="string">&quot;./seaborndata&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(tips_df.head())</span><br><span class="line">sns.pairplot(tips_df, hue = <span class="string">&#x27;sex&#x27;</span>,)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129195651651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h4 id="rugplot"><a href="#rugplot" class="headerlink" title="rugplot()"></a>rugplot()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这里用的是上面刚刚载入的数据集</span></span><br><span class="line">sns.rugplot(tips_df[<span class="string">&#x27;tip&#x27;</span>])</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210129195702475.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;seaborn入门-1-展示seaborn的各种绘图效果&quot;&gt;&lt;a href=&quot;#seaborn入门-1-展示seaborn的各种绘图效果&quot; class=&quot;headerlink&quot; title=&quot;seaborn入门(1)展示seaborn的各种绘图效果&quot;&gt;&lt;/a&gt;se</summary>
      
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="seaborn" scheme="http://example.com/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>sklearn随机森林</title>
    <link href="http://example.com/2021/11/02/python-rdf/"/>
    <id>http://example.com/2021/11/02/python-rdf/</id>
    <published>2021-11-01T17:11:37.000Z</published>
    <updated>2021-11-01T17:15:51.133Z</updated>
    
    <content type="html"><![CDATA[<h1 id="sklearn随机森林"><a href="#sklearn随机森林" class="headerlink" title="sklearn随机森林"></a>sklearn随机森林</h1><p>本文基于菜菜的sklearn教学</p><p>@[toc]</p><h2 id="随机森林分类器"><a href="#随机森林分类器" class="headerlink" title="随机森林分类器"></a>随机森林分类器</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>随机森林是一种集成算法，即运用大量不同的算法，选出最优的一个，主要是基于决策树。</p><h3 id="引入包"><a href="#引入包" class="headerlink" title="引入包"></a>引入包</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_wine</span><br></pre></td></tr></table></figure><h3 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wine = load_wine()</span><br><span class="line"><span class="built_in">print</span>(wine.data.shape)</span><br><span class="line"><span class="built_in">print</span>(wine.target)</span><br></pre></td></tr></table></figure><h3 id="划分测试集和训练集"><a href="#划分测试集和训练集" class="headerlink" title="划分测试集和训练集"></a>划分测试集和训练集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">Xtrain,Xtest,Ytrain,Ytest = train_test_split(wine.data,wine.target,test_size = <span class="number">0.3</span>)</span><br></pre></td></tr></table></figure><h3 id="核心代码"><a href="#核心代码" class="headerlink" title="核心代码"></a>核心代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rfc = RandomForestClassifier(random_state = <span class="number">0</span>)</span><br><span class="line">rfc = rfc.fit(Xtrain,Ytrain)</span><br><span class="line">score_r = rfc.score(Xtest,Ytest)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Random Forest:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(score_r))</span><br></pre></td></tr></table></figure><p>和决策树几乎一模一样，核心代码似乎也就这么几行：</p><ul><li>建立分类器rfc</li><li>带入数据进行训练</li><li>利用测试集给出评分</li></ul><h3 id="特征重要性"><a href="#特征重要性" class="headerlink" title="特征重要性"></a>特征重要性</h3><p>可以输出模型中每一个特征的重要性程度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(rfc.feature_importances_)</span><br></pre></td></tr></table></figure><p>下面是这么多次交叉验证之后所得到的准确率变化</p><h3 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h3><p>Xtest可以换成所需要预测的数据，返回对应的标签</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rfc.predict(Xtest)</span><br></pre></td></tr></table></figure><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p>交叉验证就是不断的重新划分训练集和数据集进行验证，注意交叉验证的时候是不用<code>fit()</code>的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">rfc = RandomForestClassifier(n_estimators = <span class="number">25</span>)</span><br><span class="line">rfc_s = cross_val_score(rfc,wine.data,wine.target,cv = <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">11</span>), rfc_s,label = <span class="string">&quot;RandomForest&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>下面给出十次交叉验证的得分<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210130190153741.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h3 id="参数讲解"><a href="#参数讲解" class="headerlink" title="参数讲解"></a>参数讲解</h3><p>随机森林中的参数大多数与决策树中的参数差不多，最重要的是：</p><ul><li>n_estimator 森林中树中的个数，显然个数越多结果越准确。<br>其他的建议<a class="link"   href="https://blog.csdn.net/u011301133/article/details/52562874" >看这位大佬的<i class="fas fa-external-link-alt"></i></a></li></ul><h2 id="随机森林回归"><a href="#随机森林回归" class="headerlink" title="随机森林回归"></a>随机森林回归</h2><p>分类和回归的区别其实就是一个变量是分类变量，一个变量是连续变量。对于sklearn来说几乎没什么区别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line">reg = RandomForestRegressor(n_estimators = <span class="number">100</span>,random_state = <span class="number">0</span>)</span><br><span class="line">cross_val_score(reg, boston.data, boston.target, cv = <span class="number">10</span> ,scoring = <span class="string">&quot;neg_mean_squared_error&quot;</span>)</span><br></pre></td></tr></table></figure><p>其他都和分类树一样</p><h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><p><strong>随机森林在乳腺癌数据上的调参</strong></p><h3 id="基础代码"><a href="#基础代码" class="headerlink" title="基础代码"></a>基础代码</h3><p>下面调用了乳腺癌患者的例子，给出10次交叉验证的结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data = load_breast_cancer()</span><br><span class="line"></span><br><span class="line">rfc = RandomForestClassifier(n_estimators=<span class="number">100</span>,random_state=<span class="number">90</span>)</span><br><span class="line">score_pre = cross_val_score(rfc,data.data,data.target,cv=<span class="number">10</span>).mean()</span><br><span class="line"><span class="built_in">print</span>(score_pre)</span><br></pre></td></tr></table></figure><p>最后结果为<code>0.9648809523809524</code>，还是比较准确的</p><h3 id="调参"><a href="#调参" class="headerlink" title="调参"></a>调参</h3><p>但是我还是不满意，于是我使用了200次循环，每次循环取十次交叉验证的平均值，并逐次增加树的数量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = load_breast_cancer()</span><br><span class="line"></span><br><span class="line">scorel = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">200</span>,<span class="number">10</span>):</span><br><span class="line">    rfc = RandomForestClassifier(n_estimators=i+<span class="number">1</span>,n_jobs=-<span class="number">1</span>,random_state=<span class="number">90</span>)</span><br><span class="line">    score = cross_val_score(rfc,data.data,data.target,cv=<span class="number">10</span>).mean()</span><br><span class="line">    scorel.append(score)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">max</span>(scorel),(scorel.index(<span class="built_in">max</span>(scorel))*<span class="number">10</span>)+<span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=[<span class="number">20</span>,<span class="number">5</span>])</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">201</span>,<span class="number">10</span>),scorel)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果有<img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210130190141256.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>菜菜后面还写了一堆调参的，但对我一个只打一打美赛的菜鸡好像其实用不到这么多，感兴趣的自己去b站搜菜菜的sklearn吧</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;sklearn随机森林&quot;&gt;&lt;a href=&quot;#sklearn随机森林&quot; class=&quot;headerlink&quot; title=&quot;sklearn随机森林&quot;&gt;&lt;/a&gt;sklearn随机森林&lt;/h1&gt;&lt;p&gt;本文基于菜菜的sklearn教学&lt;/p&gt;
&lt;p&gt;@[toc]&lt;/p&gt;</summary>
      
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="sklearn" scheme="http://example.com/tags/sklearn/"/>
    
    <category term="rdf" scheme="http://example.com/tags/rdf/"/>
    
  </entry>
  
  <entry>
    <title>sklearn数据预处理和特征工程</title>
    <link href="http://example.com/2021/11/02/python-data-process/"/>
    <id>http://example.com/2021/11/02/python-data-process/</id>
    <published>2021-11-01T17:09:17.000Z</published>
    <updated>2021-11-01T17:16:02.603Z</updated>
    
    <content type="html"><![CDATA[<h1 id="sklearn数据预处理和特征工程"><a href="#sklearn数据预处理和特征工程" class="headerlink" title="sklearn数据预处理和特征工程"></a>sklearn数据预处理和特征工程</h1><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="数据的无量纲化"><a href="#数据的无量纲化" class="headerlink" title="数据的无量纲化"></a>数据的无量纲化</h3><p>一般来说，当我们将数据导入模型的时候，无量纲化的可以帮我们<strong>去除量纲对模型</strong>的影响（决策树和随机森林不需要这样做，它可以处理大多数数据）<br>一般来说线性的无量纲化包括<strong>去中心化</strong>和<strong>缩放处理</strong>，中心化就是将原本的数据通过加减一个固定值使他进行平移，缩放就是对数据乘除一个固定值使其处于某一种范围之中，例如取对数。</p><h4 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h4><p><strong>归一化处理</strong>，可以将数据缩放到0-1之间<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210130213325246.png#pic_center"                      alt="在这里插入图片描述"                ></p><p>上面这个肯定会很眼熟,代码实现还是老三样</p><ul><li>实例化</li><li>用<code>fit()</code>处理数据</li><li>导出结果<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = [[-<span class="number">1</span>, <span class="number">2</span>], [-<span class="number">0.5</span>, <span class="number">6</span>], [<span class="number">0</span>, <span class="number">10</span>], [<span class="number">1</span>, <span class="number">18</span>]]</span><br><span class="line">scaler = MinMaxScaler() <span class="comment">#实例化</span></span><br><span class="line">scaler = scaler.fit(data) <span class="comment">#fit，在这里本质是生成min(x)和max(x)</span></span><br><span class="line">result = scaler.transform(data) <span class="comment">#导出结果</span></span><br></pre></td></tr></table></figure>或者也可以一步到位<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result_ = scaler.fit_transform(data)</span><br></pre></td></tr></table></figure>或者你也可以将数据归一化到其他范围<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scaler = MinMaxScaler(feature_range=</span><br><span class="line">[<span class="number">5</span>,<span class="number">10</span>])</span><br><span class="line">result = scaler.fit_transform(data)</span><br></pre></td></tr></table></figure><h4 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h4></li></ul><p><strong>标准化处理</strong>可以将数据缩放到-1-1之间<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/2021013021334539.png#pic_center"                      alt="在这里插入图片描述"                ></p><p>代码为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">data = [[-<span class="number">1</span>, <span class="number">2</span>], [-<span class="number">0.5</span>, <span class="number">6</span>], [<span class="number">0</span>, <span class="number">10</span>], [<span class="number">1</span>, <span class="number">18</span>]]</span><br><span class="line">scaler = StandardScaler() <span class="comment">#实例化</span></span><br><span class="line">scaler.fit(data) <span class="comment">#fit，本质是生成均值和方差</span></span><br><span class="line">scaler.mean_ <span class="comment">#查看均值</span></span><br><span class="line">scaler.var_ <span class="comment">#查看方差_</span></span><br><span class="line">x_std = scaler.transform(data)</span><br></pre></td></tr></table></figure><h4 id="标准化和归一化如何选择"><a href="#标准化和归一化如何选择" class="headerlink" title="标准化和归一化如何选择"></a>标准化和归一化如何选择</h4><p>在大多数机器学习里都是选择<strong>标准化</strong>来进行特征缩放的。<br>而归一化对于异常值较为敏感，优点是便于计算，可以用在图像处理等方面。</p><h3 id="填补缺失值"><a href="#填补缺失值" class="headerlink" title="填补缺失值"></a>填补缺失值</h3><p>首先导入菜菜给的泰坦尼克号数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(<span class="string">r&quot;D:\2 菜菜的sklearn直播课件\预处理数据\Narrativedata.csv&quot;</span>,index_col= <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210130212959298.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Age = data.loc[: ,<span class="string">&quot;Age&quot;</span>].values.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure><blockquote><ul><li><code>data</code>是pandas的DataFrame结构</li><li><code>data.loc[: ,&quot;Age&quot;]</code>是Age所在行，是一个字典形式的量，即索引对应年龄</li><li><code>data.loc[: ,&quot;Age&quot;].values</code>取出了字典中所有值,即取出所有年龄，是一个一维数组</li><li><code>data.loc[: ,&quot;Age&quot;].values.reshape(-1,1)</code>将其转化二维列向量，<code>reshape(a,b)</code>指的是转化为a行b列的二维向量，其中-1代表自动计算。</li></ul></blockquote><p>依然是</p><ul><li>实例化<code>SimpleImputer()</code></li><li><code>result = fit_transform(yourdata)</code></li><li><code>data.loc[:&quot;Age&quot;] = result</code><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line">imp_mean = SimpleImputer() <span class="comment">#实例化，默认均值填补</span></span><br><span class="line">imp_median = SimpleImputer(strategy=<span class="string">&quot;median&quot;</span>) <span class="comment">#用中位数填补</span></span><br><span class="line">imp_0 = SimpleImputer(strategy=<span class="string">&quot;constant&quot;</span>,fill_value=<span class="number">0</span>) <span class="comment">#用0补</span></span><br><span class="line"></span><br><span class="line">imp_mean = imp_mean.fit_transform(Age)</span><br><span class="line">imp_median = imp_median.fit_transform(Age)</span><br><span class="line">imp_0 = imp_0.fit_transform(Age)</span><br><span class="line"></span><br><span class="line"><span class="comment">#在这里我们使用中位数填补Age</span></span><br><span class="line">data.loc[:,<span class="string">&quot;Age&quot;</span>] = imp_median</span><br><span class="line">data.info()</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用众数填补Embarked</span></span><br><span class="line">Embarked = data.loc[:,<span class="string">&quot;Embarked&quot;</span>].values.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">imp_mode = SimpleImputer(strategy =<span class="string">&quot;most_frequent&quot;</span>)</span><br><span class="line">data.loc[:,<span class="string">&quot;Embarked&quot;</span>] = imp_mode.fit_transform(Embarked)</span><br><span class="line">data.info()</span><br></pre></td></tr></table></figure><code>data.loc[:,&quot;Age&quot;] = imp_median</code>这里是可以直接赋值的，虽然他两类型不同,一个是字典一个是二维数组<br>也可以<strong>直接用pands和numpy填补</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.loc[:,<span class="string">&quot;Age&quot;</span>] = data.loc[:,<span class="string">&quot;Age&quot;</span>].fillna(data.loc[:,<span class="string">&quot;Age&quot;</span>].median())</span><br></pre></td></tr></table></figure>也可以直接将缺失的数据丢掉<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data.dropna(axis=</span><br><span class="line"><span class="number">0</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><code>axis = 0</code>代表对行操作，<code>inplace = True</code>代表直接对原数据替换<h3 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h3>其实就是将<strong>文字型变量转化为数值型</strong><br>依然是三步：</li><li>实例化<code>LabelEncoder()</code></li><li><code>le.fit_transform(data.iloc[:,2])</code></li><li><code>data.iloc[:,2] = result</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">le = LabelEncoder()</span><br><span class="line">result = le.fit_transform(data.iloc[:,<span class="number">2</span>])</span><br><span class="line">data.iloc[:,<span class="number">2</span>] = result</span><br></pre></td></tr></table></figure><h3 id="二值化和分段"><a href="#二值化和分段" class="headerlink" title="二值化和分段"></a>二值化和分段</h3><h4 id="二值化"><a href="#二值化" class="headerlink" title="二值化"></a>二值化</h4><p>例如我们可以将上述数据二值化，大于30岁的赋值为1，小于30岁的赋值为0<br>嘿嘿，老三样，只是这次又得转为二维数组</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Binarizer</span><br><span class="line">X = data2.iloc[:,<span class="number">0</span>].values.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">bn = Binarizer(threshold = <span class="number">30</span>)</span><br><span class="line">result = bn.fit_transform(X)</span><br></pre></td></tr></table></figure><h4 id="分段"><a href="#分段" class="headerlink" title="分段"></a>分段</h4><p>这次KBinsDiscretizer()里面有几个重要参数</p><ul><li><strong>n_bins</strong>是分的类的数量</li><li><strong>encode</strong>是编码方式，’ordinary’,指的是返回一个整数，如分成三个类返回0，1，2构成的数列</li><li><strong>strategy</strong>有三种”uniform”是等宽分类，用最大值与最小值之差除与类的数量作为每个类的宽度,”quantile”是将每个类中的样本数分的都相同,“kmeans”是用kmeans聚类的方法来分类<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> KBinsDiscretizer</span><br><span class="line">X = data.iloc[:,<span class="number">0</span>].values.reshape(-<span class="number">1</span>,<span class="number">1</span>) </span><br><span class="line">est = KBinsDiscretizer(n_bins=<span class="number">3</span>, encode=<span class="string">&#x27;ordinal&#x27;</span>, strategy=<span class="string">&#x27;uniform&#x27;</span>)</span><br><span class="line">est.fit_transform(X) </span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;sklearn数据预处理和特征工程&quot;&gt;&lt;a href=&quot;#sklearn数据预处理和特征工程&quot; class=&quot;headerlink&quot; title=&quot;sklearn数据预处理和特征工程&quot;&gt;&lt;/a&gt;sklearn数据预处理和特征工程&lt;/h1&gt;&lt;h2 id=&quot;数据预处理</summary>
      
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="sklearn" scheme="http://example.com/tags/sklearn/"/>
    
  </entry>
  
  <entry>
    <title>sklearn主成分分析PCA</title>
    <link href="http://example.com/2021/11/02/python-pca/"/>
    <id>http://example.com/2021/11/02/python-pca/</id>
    <published>2021-11-01T17:00:55.000Z</published>
    <updated>2021-11-01T17:07:21.169Z</updated>
    
    <content type="html"><![CDATA[<h1 id="sklearn主成分分析PCA"><a href="#sklearn主成分分析PCA" class="headerlink" title="sklearn主成分分析PCA"></a>sklearn主成分分析PCA</h1><h2 id="数学原理"><a href="#数学原理" class="headerlink" title="数学原理"></a>数学原理</h2><p>给数学基础不是很好的看<br>PCA主要用于<strong>降维</strong>，比如一个人有<strong>身高，年龄，样貌，性别，智力，耐力，速度，成绩</strong>等等很多<strong>特征</strong>，<strong>每种特征便是一个维度</strong>。假如你觉得描述一个人的特征太多，你想要用<strong>一两个或几个特征</strong>就个以描述一个人，并且<strong>这几个特征包含之前提到所有特征所包含的信息</strong>，将这么原来的众多特征转化为几个特征的过程就是<strong>降维</strong>。而降维后得到的特征包含的<strong>信息量的多少也叫做贡献率</strong>，信息量越多越能够反应本质。</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>这里举一个最常用的水仙花的例子</p><h3 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h3><p>包括sklearn他的好基友们啦。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h3 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h3><p>这是一个水仙花的案例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">iris = load_iris()</span><br><span class="line">y = iris.target</span><br><span class="line">x = iris.data</span><br></pre></td></tr></table></figure><p>有<code>x.shape = (150, 4)</code>,即每朵花共有四个特征,分别为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">iris.feature_names = </span><br><span class="line">                    [<span class="string">&#x27;sepal length (cm)&#x27;</span>,</span><br><span class="line">                     <span class="string">&#x27;sepal width (cm)&#x27;</span>,</span><br><span class="line">                     <span class="string">&#x27;petal length (cm)&#x27;</span>,</span><br><span class="line">                     <span class="string">&#x27;petal width (cm)&#x27;</span>]</span><br></pre></td></tr></table></figure><p>而<code>y</code>是一个分类变量，分别为<code>[0,1,2]</code>代表三种不同的花</p><h3 id="核心代码"><a href="#核心代码" class="headerlink" title="核心代码"></a>核心代码</h3><p>还是sklearn中的老三样:</p><ul><li>实例化PCA()</li><li>调用<code>fit()</code>函数</li><li>调用<code>transform()</code>函数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components = <span class="number">2</span>)</span><br><span class="line">pca = pca.fit(x)</span><br><span class="line">x_dr = pca.transform(x)</span><br></pre></td></tr></table></figure><blockquote><p>这里<code>n_components</code>表示降维后所得到的维度<br>或者也可以直接一步到位</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_dr = PCA(<span class="number">2</span>).fit_transform(x)</span><br></pre></td></tr></table></figure></li></ul><h3 id="查看降维后所带有的信息量大小"><a href="#查看降维后所带有的信息量大小" class="headerlink" title="查看降维后所带有的信息量大小"></a>查看降维后所带有的信息量大小</h3><ul><li>两个维度信息量大小<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(pca.explained_variance_)</span><br></pre></td></tr></table></figure>可以得到<code>[4.22824171， 0.24267075]</code></li><li>两个维度贡献率</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pca.explained_variance_ratio_</span><br></pre></td></tr></table></figure><p>可以得到<code>[0.92461872, 0.05306648]</code></p><h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><p>当我们把数据降维后，可以观察其在新的维度上的分布</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line">plt.scatter(x_dr[y == <span class="number">0</span>,<span class="number">0</span>],x_dr[y == <span class="number">0</span>,<span class="number">1</span>],c = <span class="string">&quot;red&quot;</span>,label = iris.target_names[<span class="number">0</span>])</span><br><span class="line">plt.scatter(x_dr[y == <span class="number">1</span>,<span class="number">0</span>],x_dr[y == <span class="number">1</span>,<span class="number">1</span>],c = <span class="string">&quot;black&quot;</span>,label = iris.target_names[<span class="number">1</span>])</span><br><span class="line">plt.scatter(x_dr[y == <span class="number">2</span>,<span class="number">0</span>],x_dr[y == <span class="number">2</span>,<span class="number">1</span>],c = <span class="string">&quot;orange&quot;</span>,label = iris.target_names[<span class="number">2</span>])</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><blockquote><p>其中<code>x_dr[y = 0,0]用了布尔索引</code></p></blockquote><p>得到如下结果<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210201123828720.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><p>可以这是一个分簇的分布，也就是说降维之后其实已经比较好分类了</p><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><h4 id="累计方差贡献率曲线"><a href="#累计方差贡献率曲线" class="headerlink" title="累计方差贡献率曲线"></a>累计方差贡献率曲线</h4><p>当选取维度不同时累计贡献率的曲线。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pca_line = PCA().fit(x)</span><br><span class="line">plt.plot([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],np.cumsum(pca_line.explained_variance_ratio_))</span><br><span class="line">plt.xticks([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210201123816813.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h4 id="最大似然估计选择超参数"><a href="#最大似然估计选择超参数" class="headerlink" title="最大似然估计选择超参数"></a>最大似然估计选择超参数</h4><p>这种方法可以自动选出最合适的维度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pca_mle = PCA(n_components = <span class="string">&quot;mle&quot;</span>)</span><br><span class="line">pca_mle = pca_mle.fit(x)</span><br><span class="line">x_mle = pca_mle.transform(x)</span><br><span class="line">pca_mle.explained_variance_ratio_.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><p>比如上述例子为我们选了维度为3，累计贡献率高达0.994</p><h4 id="按贡献率选择"><a href="#按贡献率选择" class="headerlink" title="按贡献率选择"></a>按贡献率选择</h4><p>意味着你想要他的累计贡献率达到0.97时的维度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pca_f = PCA(n_components=<span class="number">0.97</span>,svd_solver=<span class="string">&quot;full&quot;</span>)</span><br><span class="line">pca_f = pca_f.fit(x)</span><br><span class="line">x_f = pca_f.transform(x)</span><br><span class="line"><span class="built_in">print</span>(pca_f.explained_variance_ratio_)</span><br></pre></td></tr></table></figure><p>贡献率分别为<code>[0.92461872, 0.05306648]</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;sklearn主成分分析PCA&quot;&gt;&lt;a href=&quot;#sklearn主成分分析PCA&quot; class=&quot;headerlink&quot; title=&quot;sklearn主成分分析PCA&quot;&gt;&lt;/a&gt;sklearn主成分分析PCA&lt;/h1&gt;&lt;h2 id=&quot;数学原理&quot;&gt;&lt;a href</summary>
      
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="sklearn" scheme="http://example.com/tags/sklearn/"/>
    
    <category term="pca" scheme="http://example.com/tags/pca/"/>
    
  </entry>
  
  <entry>
    <title>sklearn聚类算法Kmeans</title>
    <link href="http://example.com/2021/11/02/python-kmeans/"/>
    <id>http://example.com/2021/11/02/python-kmeans/</id>
    <published>2021-11-01T16:55:12.000Z</published>
    <updated>2021-11-01T17:05:38.319Z</updated>
    
    <content type="html"><![CDATA[<h1 id="sklearn聚类算法Kmeans"><a href="#sklearn聚类算法Kmeans" class="headerlink" title="sklearn聚类算法Kmeans"></a>sklearn聚类算法Kmeans</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>聚类算法是一种<strong>无监督学习算法</strong>，也就是说它不需要<strong>标签</strong>,只需要大量的特征就可以把数据集聚类，然后聚类在自己给他贴标签。 这里Kmeans的具体原理不作详述。</p><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><h3 id="数据生成"><a href="#数据生成" class="headerlink" title="数据生成"></a>数据生成</h3><p>通过sklearn自带的<code>make_blobs</code>函数可以生成聚类所需的数据集，注意，所生成的数据集是几个<strong>分簇</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">500</span>,n_features=<span class="number">2</span>,centers=<span class="number">4</span>,random_state=<span class="number">1</span>)</span><br><span class="line">fig, ax1 = plt.subplots(<span class="number">1</span>)</span><br><span class="line">ax1.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>],marker=<span class="string">&#x27;o&#x27;</span>,s=<span class="number">8</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210201163842174.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><p>上面是聚类前的图像，其中<code>X</code>是一个二维数组，每行有一个点的横坐标和纵坐标，<code>y</code>是已经给好的分类，是一个一维的数组，代表不同数据所在的簇。，下图是实际按不同簇分开的数据<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210201163856733.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h3 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h3><p>聚类依然是通过</p><ul><li>类的实例化</li><li>fit()函数</li><li>可以直接同<code>.labels_</code>或<code>.fit_predict</code>得到分类结果<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">cluster = KMeans(n_clusters = <span class="number">3</span>, random_state = <span class="number">0</span>)</span><br><span class="line">cluster = cluster.fit(X)</span><br><span class="line">y_pred = cluster.labels_</span><br><span class="line"><span class="comment">#y_pred = cluster.fit_predict(X)</span></span><br></pre></td></tr></table></figure>所得到的y_pred是一个一维矩阵，包含了每一个点对应的类分类，分别为0,1,2</li></ul><h4 id="类的质心"><a href="#类的质心" class="headerlink" title="类的质心"></a>类的质心</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">centroid = cluster.cluster_centers_</span><br></pre></td></tr></table></figure><p><code>centroid == [[-7.09306648, -8.10994454], [-1.54234022,  4.43517599], [-8.0862351 , -3.5179868 ]]</code>代表所分三类的质心。可以说这个点的特征最能代表这一个分类</p><h4 id="聚类的评估"><a href="#聚类的评估" class="headerlink" title="聚类的评估"></a>聚类的评估</h4><p>Inertia指每个样本点到其中心点的距离之和</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inertia = cluster.inertia_</span><br></pre></td></tr></table></figure><p>但似乎对于某些细长的类来说表现显然不太好，所以用<strong>轮廓系数</strong>来评估。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score</span><br><span class="line">silhouette_score(X,y_pred)</span><br></pre></td></tr></table></figure><h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">color = [<span class="string">&quot;red&quot;</span>,<span class="string">&quot;pink&quot;</span>,<span class="string">&quot;orange&quot;</span>,<span class="string">&quot;gray&quot;</span>]</span><br><span class="line">fig, ax1 = plt.subplots(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    ax1.scatter(X[y_pred==i, <span class="number">0</span>], X[y_pred==i, <span class="number">1</span>]</span><br><span class="line">     ,marker=<span class="string">&#x27;o&#x27;</span></span><br><span class="line">     ,s=<span class="number">8</span></span><br><span class="line">     ,c=color[i]</span><br><span class="line">     )</span><br><span class="line">ax1.scatter(centroid[:,<span class="number">0</span>],centroid[:,<span class="number">1</span>]</span><br><span class="line">     ,marker=<span class="string">&quot;x&quot;</span></span><br><span class="line">     ,s=<span class="number">15</span></span><br><span class="line">     ,c=<span class="string">&quot;black&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>那几个黑叉叉就是质心<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210201163926542.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h4 id="分成4类会怎么样"><a href="#分成4类会怎么样" class="headerlink" title="分成4类会怎么样"></a>分成4类会怎么样</h4><p><strong>会更合理</strong><br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210201163940755.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;sklearn聚类算法Kmeans&quot;&gt;&lt;a href=&quot;#sklearn聚类算法Kmeans&quot; class=&quot;headerlink&quot; title=&quot;sklearn聚类算法Kmeans&quot;&gt;&lt;/a&gt;sklearn聚类算法Kmeans&lt;/h1&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="sklearn" scheme="http://example.com/tags/sklearn/"/>
    
    <category term="kmeans" scheme="http://example.com/tags/kmeans/"/>
    
  </entry>
  
  <entry>
    <title>python支持向量机SVM (sklearn)</title>
    <link href="http://example.com/2021/11/01/python%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM%20(sklearn)/"/>
    <id>http://example.com/2021/11/01/python%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM%20(sklearn)/</id>
    <published>2021-11-01T15:04:54.000Z</published>
    <updated>2021-11-01T17:06:34.864Z</updated>
    
    <content type="html"><![CDATA[<h1 id="sklearn支持向量机SVM"><a href="#sklearn支持向量机SVM" class="headerlink" title="sklearn支持向量机SVM"></a>sklearn支持向量机SVM</h1><h2 id="原理概述"><a href="#原理概述" class="headerlink" title="原理概述"></a>原理概述</h2><p>说实话以前用支持向量机都是直接套进去的，不过现在看了看菜菜提供数学原理发现其实挺有意思(<del>是超有意思！！</del>)。此处就不详述了，这原理到处都是。反正这SVM和决策树一样,<strong>有支持向量分类(SVC)和支持向量回归(SVR)</strong>.</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>下面是一个SVC的案例</p><h3 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h3 id="生成数据集"><a href="#生成数据集" class="headerlink" title="生成数据集"></a>生成数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X,y = make_blobs(n_samples=<span class="number">50</span>, centers=<span class="number">2</span>, random_state=<span class="number">0</span>,cluster_std=<span class="number">0.6</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>],X[:,<span class="number">1</span>],c=y,s=<span class="number">50</span>,cmap=<span class="string">&quot;rainbow&quot;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202165752700.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><h3 id="核心代码"><a href="#核心代码" class="headerlink" title="核心代码"></a>核心代码</h3><p>模型本身并不难，就是要画出相应的图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">clf = SVC(kernel = <span class="string">&quot;linear&quot;</span>).fit(X,y)</span><br><span class="line"><span class="built_in">print</span>(clf.predict(X))</span><br></pre></td></tr></table></figure><p>上述例子预测又对X自己预测了一变。按照核心代码依旧延续sklearn的风格，十分简单。</p><ul><li>实例化</li><li>fit()</li><li>predict(）。</li></ul><p>可视化可能优点麻烦,需要用到下面这个函数。这个函数只需输入<code>clf</code>即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_svc_decision_function</span>(<span class="params">model,ax=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> ax <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">    xlim = ax.get_xlim()</span><br><span class="line">    ylim = ax.get_ylim()</span><br><span class="line">    x = np.linspace(xlim[<span class="number">0</span>],xlim[<span class="number">1</span>],<span class="number">30</span>)</span><br><span class="line">    y = np.linspace(ylim[<span class="number">0</span>],ylim[<span class="number">1</span>],<span class="number">30</span>)</span><br><span class="line">    Y,X = np.meshgrid(y,x)</span><br><span class="line">    xy = np.vstack([X.ravel(), Y.ravel()]).T</span><br><span class="line">    <span class="comment">#decision_function这个函数可以返回给定的x,y点到决策边界（也就是点到SVM所得到划分线的距离）</span></span><br><span class="line">    P = model.decision_function(xy).reshape(X.shape)</span><br><span class="line">    ax.contour(X, Y, P,colors=<span class="string">&quot;k&quot;</span>,levels=[-<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],alpha=<span class="number">0.5</span>,linestyles=[<span class="string">&quot;--&quot;</span>,<span class="string">&quot;-&quot;</span>,<span class="string">&quot;--&quot;</span>])</span><br><span class="line">    ax.set_xlim(xlim)</span><br><span class="line">    ax.set_ylim(ylim)</span><br></pre></td></tr></table></figure><blockquote><p>函数大概思路就是首先生成一个<strong>网格</strong>，然后<strong>计算网格中各个点到决策边界的距离</strong>，最后绘制<strong>等高线</strong>(算出的距离相等的一条线)。</p></blockquote><p>则可以写作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">clf = SVC(kernel = <span class="string">&quot;linear&quot;</span>).fit(X,y)</span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>],X[:,<span class="number">1</span>],c=y,s=<span class="number">50</span>,cmap=<span class="string">&quot;rainbow&quot;</span>)</span><br><span class="line">plot_svc_decision_function(clf)</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202165825224.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><p>其中<strong>灰色实线</strong>就是<strong>决策边界</strong>，<strong>虚线之间的距离</strong>就是<strong>边际</strong>。而SVM就是要找到<strong>边际最大的一条决策边界</strong>，而上面那<strong>三个穿虚线而过的点</strong>就是<strong>支持向量</strong>（最下面那个红色不算），<strong>也就是离决策边界最近的3个点</strong>。</p><h3 id="线性不可分的情况"><a href="#线性不可分的情况" class="headerlink" title="线性不可分的情况"></a>线性不可分的情况</h3><p>这就是整个SVM我觉得最关键也最有意思的地方。从上面的图我们能够知道SVM实际上是找到一个<strong>超平面</strong>将各点分开。如果能找到自然就是<strong>线性可分</strong>的，<strong>那如果找不到呢？</strong></p><blockquote><p><strong>超平面</strong>就是比<strong>当前空间维度低一个维度的分界</strong>，对于<strong>二维平面来说是一条线</strong>，对于<strong>三维空间是一个面</strong>。</p></blockquote><p>对于这么一个案例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_circles</span><br><span class="line">X,y = make_circles(<span class="number">100</span>, factor=<span class="number">0.1</span>, noise=<span class="number">.1</span>)</span><br><span class="line">X.shape</span><br><span class="line">y.shape</span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>],X[:,<span class="number">1</span>],c=y,s=<span class="number">50</span>,cmap=<span class="string">&quot;rainbow&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202165853324.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><p>我们可以看出，<strong>不可能存在一条直线</strong>，能将红色和蓝色分开，所以它是<strong>线性不可分的</strong>，怎么办呢？答案是<strong>升维！！！</strong></p><p>对于原来每一个点，我们使用一个<strong>映射函数</strong>，使得从原来的<strong>二维点</strong>变为原来的<strong>三维点</strong>。对于原来一个点<strong>有(x0,y0)</strong>,<br><strong>从(x0,y0)变为(x1,y1,z1)</strong>,其中<strong>z1有</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x1 = x0; y1 = y0; z1 = e^&#123;-(x^2+y^2)&#125; </span><br></pre></td></tr></table></figure><p>先别想这个函数是怎么来的，让我们先看看映射后的结果怎么样<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202170007694.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><p>这个结果非常的amazing啊，红色的点浮起来了，现在只需要用一个<strong>平面</strong>就能把红色和蓝色隔开,也就是说，<strong>升维之后线性可分了！</strong>(<del>当时就把我看湿了</del></p><p>下面是上面这个案例的完整代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_circles</span><br><span class="line">X,y = make_circles(<span class="number">100</span>, factor=<span class="number">0.1</span>, noise=<span class="number">.1</span>)</span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>],X[:,<span class="number">1</span>],c=y,s=<span class="number">50</span>,cmap=<span class="string">&quot;rainbow&quot;</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_svc_decision_function</span>(<span class="params">model,ax=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> ax <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">    xlim = ax.get_xlim()</span><br><span class="line">    ylim = ax.get_ylim()</span><br><span class="line">    x = np.linspace(xlim[<span class="number">0</span>],xlim[<span class="number">1</span>],<span class="number">30</span>)</span><br><span class="line">    y = np.linspace(ylim[<span class="number">0</span>],ylim[<span class="number">1</span>],<span class="number">30</span>)</span><br><span class="line">    Y,X = np.meshgrid(y,x)</span><br><span class="line">    xy = np.vstack([X.ravel(), Y.ravel()]).T</span><br><span class="line">    P = model.decision_function(xy).reshape(X.shape)</span><br><span class="line">    ax.contour(X, Y, P,colors=<span class="string">&quot;k&quot;</span>,levels=[-<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],alpha=<span class="number">0.5</span>,linestyles=[<span class="string">&quot;--&quot;</span>,<span class="string">&quot;-&quot;</span>,<span class="string">&quot;--&quot;</span>])</span><br><span class="line">    ax.set_xlim(xlim)</span><br><span class="line">    ax.set_ylim(ylim)</span><br><span class="line">clf = SVC(kernel = <span class="string">&quot;linear&quot;</span>).fit(X,y)</span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>],X[:,<span class="number">1</span>],c=y,s=<span class="number">50</span>,cmap=<span class="string">&quot;rainbow&quot;</span>)</span><br><span class="line">plot_svc_decision_function(clf)</span><br><span class="line">r = np.exp(-(X**<span class="number">2</span>).<span class="built_in">sum</span>(<span class="number">1</span>))</span><br><span class="line">rlim = np.linspace(<span class="built_in">min</span>(r),<span class="built_in">max</span>(r),<span class="number">30</span>)</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits <span class="keyword">import</span> mplot3d</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_3D</span>(<span class="params">elev=<span class="number">30</span>,azim=<span class="number">30</span>,X=X,y=y</span>):</span></span><br><span class="line">    ax = plt.subplot(projection=<span class="string">&quot;3d&quot;</span>)</span><br><span class="line">    ax.scatter3D(X[:,<span class="number">0</span>],X[:,<span class="number">1</span>],r,c=y,s=<span class="number">50</span>,cmap=<span class="string">&#x27;rainbow&#x27;</span>)</span><br><span class="line">    ax.view_init(elev=elev,azim=azim)</span><br><span class="line">    ax.set_xlabel(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">    ax.set_zlabel(<span class="string">&quot;r&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="comment">#下面这个如果你用的是jupyter就可以互动了</span></span><br><span class="line"><span class="comment">#from ipywidgets import interact,fixed</span></span><br><span class="line"><span class="comment">#interact(plot_3D,elev=[0,30],azip=(-180,180),X=fixed(X),y=fixed(y))</span></span><br><span class="line"><span class="comment">#plt.show()</span></span><br></pre></td></tr></table></figure><h3 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h3><p>所以说上面这个映射函数到底是怎么来的呢，什么是核函数，又和<strong>核函数</strong>又什么关系呢？<br>首先SVM最终的决策函数是<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202165911151.png#pic_center"                      alt="在这里插入图片描述"                ></p><ul><li>f(x_test)是最终的分类，定义为{-1,1}</li><li>其中sign是符号函数，大于0取1，小于0取-1。</li><li>y是标签，二分类有两个标签，取{-1,1}</li><li>x_i是支持向量</li><li>x_test是测试向量</li><li>b是一个常数</li></ul><p>很显然我们要计算<strong>x_i与x_test</strong>之间的<strong>内积</strong>,当我们<strong>升维</strong>之后，我们要算的的<strong>内积是映射(升维)后的内积</strong>。<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202165928310.png#pic_center"                      alt="在这里插入图片描述"                ></p><p>那么我们定义核函数：<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202165943334.png#pic_center"                      alt="在这里插入图片描述"                ></p><p>现在我们就<strong>只需要直接把两个向量带入核函数，而不用先映射成高维再算内积</strong>。这其实省去了很多麻烦，因为计算映射其实挺复杂的。<br>注意，正是因为再<strong>SVM中我们只用到了高维函数的内积，所以只需要计算核函数即可</strong>，有了核函数，我们便能再<strong>低维计算高维的内积</strong>,(<del>这是一次低维生物对高维发起的伟大挑战</del>)显然我们有，只要<strong>映射函数不同，核函数就不同</strong>。<br>下面是sklearn中的几个核函数，个人建议用”rbf”，至于每一个核函数对应的映射函数，自己百度吧。<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202170029147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202170111226.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><p>并且有</p><ul><li><strong>线性核，尤其是多项式核函数在高次项时计算非常缓慢</strong></li><li><strong>rbf和多项式核函数都不擅长处理量纲不统一的数据集</strong><br>所以需要针对其进行标准化<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">X = StandardScaler().fit_transform(X)</span><br></pre></td></tr></table></figure></li></ul><h3 id="重要参数C-软间隔和硬间隔"><a href="#重要参数C-软间隔和硬间隔" class="headerlink" title="重要参数C(软间隔和硬间隔)"></a>重要参数C(软间隔和硬间隔)</h3><p><strong>c:</strong></p><blockquote><p>浮点数，默认1，必须大于等于0，可不填<br>松弛系数的惩罚项系数。如果<strong>C值设定比较大</strong>，那<strong>SVC可能会选择边际较小</strong>的，能够更好地分类所有训练点的决策边界，不过模型的训练时间也会更长。如果<strong>C的设定值较小</strong>，那<strong>SVC会尽量最大化边界</strong>，决策功能会更简单，但代价是训练的准确度。换句话说，C在SVM中的影响就像正则化参数对逻辑回归的影响.</p></blockquote><h3 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202170125919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><p>1是少数类，0是多数类</p><ul><li><strong>准确率</strong>：Accuracy，所有预测正确的样本除以总样本,(11+00)/(11+10+01+00)</li><li><strong>精确率</strong>：Precision，预测的少数类中，真正的少数类的占比。11/(11+01)</li><li><strong>召回率</strong> ：Recall，又被称为敏感度(sensitivity)，真正率，查全率，表示所有真实为1的样本中，被我们预测正确的样本所占的比例,11/(11+10).</li><li><strong>假负率</strong>：False Negative Rate,1-Recall。没召回的占少数类的占比。10/（11+10）</li><li><strong>特异度</strong>：Specificity,表示所有真实为0的样本中，被正确预测为0的样本所占的比例，00/（01+00）</li><li><strong>假正率</strong>：False Positive Rate，1 - specificity就是一个模型将多数类判断错误的能力，01/(01+00)</li><li><strong>ROC曲线</strong>，横轴为假正率(FPR)，纵轴为召回率(Recall)，当曲线越往左上角偏说明效果越好，。</li><li><strong>AUC面积</strong>，它代表了ROC曲线下方的面积，这个面积越大，代表ROC曲线越接近左上角，模型就越好。<h3 id="小案例"><a href="#小案例" class="headerlink" title="小案例"></a>小案例</h3></li><li>首先生成数据集并带入模型训练<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line">class_1 = <span class="number">500</span> <span class="comment">#类别1有500个样本</span></span><br><span class="line">class_2 = <span class="number">50</span> <span class="comment">#类别2只有50个</span></span><br><span class="line">centers = [[<span class="number">0.0</span>, <span class="number">0.0</span>], [<span class="number">2.0</span>, <span class="number">2.0</span>]] <span class="comment">#设定两个类别的中心</span></span><br><span class="line">clusters_std = [<span class="number">1.5</span>, <span class="number">0.5</span>] <span class="comment">#设定两个类别的方差，通常来说，样本量比较大的类别会更加松散</span></span><br><span class="line">X, y = make_blobs(n_samples=[class_1, class_2],centers=centers,cluster_std=clusters_std,random_state=<span class="number">0</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=<span class="string">&quot;rainbow&quot;</span>,s=<span class="number">10</span>)</span><br><span class="line">clf_proba = SVC(kernel=<span class="string">&quot;linear&quot;</span>,C=<span class="number">1.0</span>,probability=<span class="literal">True</span>).fit(X,y)</span><br></pre></td></tr></table></figure><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202170141184.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></li></ul><ul><li>其次把个点所预测得到的概率放入DataFrame里<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">prob = clf_proba.predict_proba(X)</span><br><span class="line"><span class="comment">#将样本和概率放到一个DataFrame中</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">prob = pd.DataFrame(prob)</span><br><span class="line">prob.columns = [<span class="string">&quot;0&quot;</span>,<span class="string">&quot;1&quot;</span>]</span><br></pre></td></tr></table></figure></li><li>找出最佳阈值并画出ROC曲线并得到相应的FPR和Recall，以及AUC</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">FPR, recall, thresholds = roc_curve(y,prob.loc[:,<span class="string">&quot;1&quot;</span>], pos_label=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#此时的threshold就不是一个概率值，而是距离值中的阈值了，所以它可以大于1，也可以为负</span></span><br><span class="line"><span class="comment">#找到最佳阈值</span></span><br><span class="line">maxindex = (recall - FPR).tolist().index(<span class="built_in">max</span>(recall - FPR))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;thresholds:&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(thresholds[maxindex])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;recall:&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(recall[maxindex])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;FPR:&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(FPR[maxindex])</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score <span class="keyword">as</span> AUC</span><br><span class="line">area = AUC(y,clf_proba.decision_function(X))</span><br><span class="line"></span><br><span class="line">plt.scatter(FPR[maxindex],recall[maxindex],c=<span class="string">&quot;black&quot;</span>,s=<span class="number">30</span>)</span><br><span class="line"><span class="comment">#把上述代码放入这段代码中：</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(FPR, recall, color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;ROC curve (area = %0.2f)&#x27;</span> % area)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.scatter(FPR[maxindex],recall[maxindex],c=<span class="string">&quot;black&quot;</span>,s=<span class="number">30</span>)</span><br><span class="line">plt.xlim([-<span class="number">0.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.ylim([-<span class="number">0.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Recall&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Receiver operating characteristic example&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;lower right&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202170241370.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><ul><li>最后进行预测，得出结果<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(prob.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> prob.loc[i,<span class="string">&quot;1&quot;</span>] &gt; thresholds[maxindex]:</span><br><span class="line">        prob.loc[i,<span class="string">&quot;pred&quot;</span>] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        prob.loc[i,<span class="string">&quot;pred&quot;</span>] = <span class="number">0</span></span><br><span class="line">prob[<span class="string">&quot;y_true&quot;</span>] = y</span><br><span class="line">prob = prob.sort_values(by=<span class="string">&quot;1&quot;</span>,ascending=<span class="literal">False</span>)</span><br><span class="line">prob</span><br></pre></td></tr></table></figure></li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/2021020217041740.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25ld3N1bnNvbg==,size_16,color_FFFFFF,t_70#pic_center"                      alt="在这里插入图片描述"                ></p><ul><li>得到混淆矩阵来评估<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix <span class="keyword">as</span> CM, precision_score <span class="keyword">as</span> P, recall_score <span class="keyword">as</span> R</span><br><span class="line">cm = CM(prob.loc[:,<span class="string">&quot;y_true&quot;</span>],prob.loc[:,<span class="string">&quot;pred&quot;</span>],labels=[<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">cm</span><br></pre></td></tr></table></figure><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/20210202170442247.png#pic_center"                      alt="在这里插入图片描述"                ></li></ul><p><strong>PS:这个案例用的是核函数是线性核，但又试了一遍还是‘rbf’比较好</strong>,<br><strong>并且其实不一定需要最佳阈值，要结合实际来看。</strong><br>例如，三星手机发生爆炸，三星想要召回率能达到100%，即宁可把没有问题的手机召回，也不能放过任何一个有问题的手机，阈值也要相应调整。</p><h3 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h3><p>多分类其实也很简单，应该是sklearn的多分类很简单，数学原理十分可怕。区别就是输入的Y多了几个分类而已。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clf = SVC(decision_function_shape=<span class="string">&#x27;ovo&#x27;</span>) clf.fit(X, Y)</span><br></pre></td></tr></table></figure><p>上面用的是ovo(one vs one)，也就是每一个类两两组合来构建,也可以选择’ovr’速度更快，效果不怎么样。</p><h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><h4 id="参数class-weight"><a href="#参数class-weight" class="headerlink" title="参数class_weight"></a>参数class_weight</h4><p>如果你想追求最高的召回率，宁可错杀不可放过，那么<code>class_weight = &quot;balanced&quot;</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clf = SVC(kernel = kernel ,gamma=<span class="string">&quot;auto&quot;</span>,degree = <span class="number">1</span>,cache_size = <span class="number">5000</span>,class_weight = <span class="string">&quot;balanced&quot;</span>).fit(Xtrain, Ytrain)</span><br></pre></td></tr></table></figure><p>如果还想再高，那么<code>class_weight = &#123;1:10&#125;</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;sklearn支持向量机SVM&quot;&gt;&lt;a href=&quot;#sklearn支持向量机SVM&quot; class=&quot;headerlink&quot; title=&quot;sklearn支持向量机SVM&quot;&gt;&lt;/a&gt;sklearn支持向量机SVM&lt;/h1&gt;&lt;h2 id=&quot;原理概述&quot;&gt;&lt;a href</summary>
      
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="sklearn" scheme="http://example.com/tags/sklearn/"/>
    
    <category term="svm" scheme="http://example.com/tags/svm/"/>
    
  </entry>
  
  <entry>
    <title>Pybind和cmake联合使用</title>
    <link href="http://example.com/2021/11/01/pybind-cmake/"/>
    <id>http://example.com/2021/11/01/pybind-cmake/</id>
    <published>2021-11-01T13:09:35.000Z</published>
    <updated>2021-11-01T17:04:28.010Z</updated>
    
    <content type="html"><![CDATA[<h1 id="pybind11与cmake的联合使用"><a href="#pybind11与cmake的联合使用" class="headerlink" title="pybind11与cmake的联合使用"></a>pybind11与cmake的联合使用</h1><h1 id="github传送门"><a href="#github传送门" class="headerlink" title="github传送门"></a><a class="link"   href="https://github.com/newsun-boki/pybind11-tutorial" >github传送门<i class="fas fa-external-link-alt"></i></a></h1><p>因为pybind11官方教程我并没有找到与cmake的联合使用，导致我不会写CMakeLists。然后其实也不是很难，发个帖子记录一下.<br>帮助你在python中使用cmake中的函数,理论上你只需要点进上面的链接就好。下面是README。</p><h2 id="step1"><a href="#step1" class="headerlink" title="step1"></a>step1</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pytest</span><br></pre></td></tr></table></figure><h2 id="step2"><a href="#step2" class="headerlink" title="step2"></a>step2</h2><p>你必须要把pybind11和CMakeLists.txt放到一个文件下。pybind11是在github下载的官方仓库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/pybind/pybind11.git</span><br></pre></td></tr></table></figure><p>这里我已经下好了，你需要做的是在pybind11下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">cmake --build . --config Release --target check</span><br></pre></td></tr></table></figure><h2 id="step3"><a href="#step3" class="headerlink" title="step3"></a>step3</h2><p>使用这个简单的官方代码example.cpp</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pybind11/pybind11.h&gt;</span></span></span><br><span class="line"><span class="keyword">namespace</span> py = pybind11;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> i + j;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(example, m) &#123;</span><br><span class="line">    m.<span class="built_in">doc</span>() = <span class="string">&quot;pybind11 example plugin&quot;</span>; <span class="comment">// optional module docstring</span></span><br><span class="line"></span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">&quot;add&quot;</span>, &amp;add, <span class="string">&quot;A function which adds two numbers&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>CMakeLists也很简单</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cmake_minimum_required(VERSION 2.8.12)</span><br><span class="line">project(example)   </span><br><span class="line"></span><br><span class="line">add_subdirectory(pybind11)</span><br><span class="line">pybind11_add_module(example example.cpp)</span><br></pre></td></tr></table></figure><p>上面有些关于pybind11的东西，所以<strong>必须要把CMakeLists和pybind11放在同一路径</strong>下。</p><h2 id="step4"><a href="#step4" class="headerlink" title="step4"></a>step4</h2><p>cmake编译这个东西。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">make</span><br></pre></td></tr></table></figure><p>会生成一个很长的.so文件，这个文件就是能够在python中调用c++的关键。<br>当你使用python调用c++函数时，请确保.so文件与python文件在同一目录下。</p><h2 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h2><p>可以直接在终端测试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> example</span><br><span class="line">example.add(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">[out]: <span class="number">7</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;pybind11与cmake的联合使用&quot;&gt;&lt;a href=&quot;#pybind11与cmake的联合使用&quot; class=&quot;headerlink&quot; title=&quot;pybind11与cmake的联合使用&quot;&gt;&lt;/a&gt;pybind11与cmake的联合使用&lt;/h1&gt;&lt;h1 i</summary>
      
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="c++" scheme="http://example.com/tags/c/"/>
    
  </entry>
  
</feed>
